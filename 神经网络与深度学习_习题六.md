# 习题六

**习题6-1**

**分析延时神经网络、卷积神经网络和循环神经网络的异同点。**

答：

相同点：三种神经网络都共享权重。

不同点：

1.延时神经网络当前层神经元的活性值仅依赖于前一层的最近的K个时刻的活性值，而循环神经网络当前神经元的活性值依赖于前一层的所有活性值。

2.循环神经网络是在时间上共享权重，卷积神经网络在空间上共享权重。

<hr>

**习题6-2**

**推导公式(6.40)和公式(6.41)中的梯度**

解：

公式(6.40)：$\frac{∂L}{∂W}=\sum_{t=1}^{T}\sum_{k=1}^{t}\delta_{t,k}x^T_k$

公式(6.41)：$\frac{∂L}{∂b}=\sum_{t=1}^{T}\sum_{k=1}^{t}\delta_{t,k}$

先证明(6.40)：

$\frac{∂L}{∂W}=\sum_{t=1}^{T}\frac{∂L_t}{∂W}$

$\frac{∂L_t}{∂\omega_{i,j}}=\sum_{k=1}^{t}\frac{∂^+z_k}{∂\omega_{i,j}}\frac{∂L_t}{∂z_k}\\=\sum_{k=1}^{t}[0,...,[x_k]_j,...,0][\delta_{t,k}]_i$

写成矩阵形式：

$\frac{∂L_t}{∂W}=\sum_{k=1}^{t}\delta_{t,k}x^T_k$

因此：

$\frac{∂L}{∂W}=\sum_{t=1}^{T}\frac{∂L_t}{∂W}=\sum_{t=1}^{T}\sum_{k=1}^{t}\delta_{t,k}x^T_k$

同理可证(6.41)：

$\frac{∂L}{∂b}=\sum_{t=1}^{T}\frac{∂L_t}{∂b}$

$\frac{∂L_t}{∂b_{i,j}}=\sum_{k=1}^{t}\frac{∂^+z_k}{∂b_{i,j}}\frac{∂L_t}{∂z_k}\\=\sum_{k=1}^{t}[0,...,[1]_j,...,0][\delta_{t,k}]_i$

写成矩阵形式：

$\frac{∂L_t}{∂b}=\sum_{k=1}^{t}\delta_{t,k}$

因此：

$\frac{∂L}{∂b}=\sum_{t=1}^{T}\frac{∂L_t}{∂b}=\sum_{t=1}^{T}\sum_{k=1}^{t}\delta_{t,k}$

<hr>

**习题6-3**

**当使用公式(6.50)作为循环神经网络的状态更新公式时，分析其可能存在梯度爆炸的原因并给出解决方法。**

解：

公式(6.50)：$h_t=h_t+g(x_t,h_{t-1};\theta)$

存在梯度爆炸的原因：

令$z_k=Uh_{k-1}+Wx_k+b$为第k时刻函数g(*)的输入，在计算误差项$\delta_{t,k}=\frac{∂L_t}{∂z_k}$时，梯度可能会过大，从而导致梯度爆炸问题。

解决方法：采用门控循环单元GRU。

GRU的状态更新方式为：$h_t=z_t⊙h_{t-1}+(1-z_t)⊙g(x_t,h_{t-1};\theta)$

<hr>

**习题6-4**

**推导LSTM网络中参数的梯度，并分析其避免梯度消失的效果**

解：

